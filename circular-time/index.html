<!doctype html><html lang=en-us><head><title>Circular Time // A fractal spectrum of tales</title>
<meta charset=utf-8><meta name=generator content="Hugo 0.139.4"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Marcello Seri"><meta name=description content="Free thoughts of a geeky mathematician"><meta http-equiv=Permissions-Policy content="interest-cohort=()"><link rel=stylesheet href=https://www.mseri.me/css/main.min.fb6dd6e5b8f0b7c4a9008884f1a95d7a84ef20fb9c190bcbbd87b6ff85f8fb9b.css><meta name=twitter:card content="summary"><meta name=twitter:title content="Circular Time"><meta name=twitter:description content="â€™Forty-two,â€™ said Deep Thought, with infinite majesty and calm. â€“ Douglas Adams, The Hitchhikerâ€™s Guide to the Galaxy
The narrative on AI keeps swinging between panicked existential threats and overoptimistic hype. Last week, while flu forcefully made sure I sayed in bed, I had time to read some articles in my backlog and really found it disappointing how the discussion has stagnated and keeps revolving around the same points.
None of the ideas look anywhere new. In The Hitchhikerâ€™s Guide to the Galaxy, Douglas Adams already brilliantly satirized on the quest for superintelligence and what will happen with it."><meta property="og:url" content="https://www.mseri.me/circular-time/"><meta property="og:site_name" content="A fractal spectrum of tales"><meta property="og:title" content="Circular Time"><meta property="og:description" content="â€™Forty-two,â€™ said Deep Thought, with infinite majesty and calm. â€“ Douglas Adams, The Hitchhikerâ€™s Guide to the Galaxy
The narrative on AI keeps swinging between panicked existential threats and overoptimistic hype. Last week, while flu forcefully made sure I sayed in bed, I had time to read some articles in my backlog and really found it disappointing how the discussion has stagnated and keeps revolving around the same points.
None of the ideas look anywhere new. In The Hitchhikerâ€™s Guide to the Galaxy, Douglas Adams already brilliantly satirized on the quest for superintelligence and what will happen with it."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-17T10:15:42+01:00"><meta property="article:modified_time" content="2026-02-17T10:15:42+01:00"><meta property="article:tag" content="Philosophy"><meta property="article:tag" content="Time"><meta property="article:tag" content="Ai"><meta property="article:tag" content="Rant"></head><body><header class=app-header><a href=https://www.mseri.me/><img class=app-header-avatar src=/images/gauss_logo.png alt="Marcello Seri"></a><h1>A fractal spectrum of tales</h1><p>Free thoughts of a geeky mathematician</p><div class=app-header-social><a target=_blank href=https://github.com/mseri rel="noreferrer noopener me"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github"><title>github</title><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a>
<a target=_blank href=https://mathstodon.xyz/@mseri rel="noreferrer noopener me"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-mastodon"><title>mastodon</title><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18.648 15.254C16.832 17.017 12 16.88 12 16.88a18.262 18.262.0 01-3.288-.256c1.127 1.985 4.12 2.81 8.982 2.475-1.945 2.013-13.598 5.257-13.668-7.636L4 10.309c0-3.036.023-4.115 1.352-5.633C7.023 2.766 12 3.01 12 3.01s4.977-.243 6.648 1.667C19.977 6.195 20 7.274 20 10.31s-.456 4.074-1.352 4.944z"/><path d="M12 11.204V8.278C12 7.02 11.105 6 10 6S8 7.02 8 8.278V13m4-4.722C12 7.02 12.895 6 14 6s2 1.02 2 2.278V13"/></svg></a>
<a target=_blank href=https://bsky.app/profile/mseri.me rel="noreferrer noopener me"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-twitter"><title>twitter</title><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a>
<a target=_blank href=https://academic.mseri.me rel="noreferrer noopener me"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-award"><title>award</title><circle cx="12" cy="8" r="7"/><polyline points="8.21 13.89 7 23 12 20 17 23 15.79 13.88"/></svg></a></div><div style=margin-top:30px><h3 style=margin-bottom:10px>My podcasts</h4><a href=https://podcasters.spotify.com/pod/show/not-just-numbers><img src=/images/njn.jpg alt="Cover of the pocast it's not just numbers" class=image width=105px>
</a>&nbsp;
<a href=https://linktr.ee/degreesoffreedom><img src=/images/dof.jpg alt="Cover of the podcast degrees of freedom" class=image width=105px></a></div></header><main class=app-container><article class=post><header class=post-header><h1 class=post-title>Circular Time</h1><div class=post-meta><div><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar"><title>calendar</title><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
Feb 17, 2026</div><div><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock"><title>clock</title><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
3 min read</div><div><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag"><title>tag</title><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg>
<a class=tag href=https://www.mseri.me/tags/philosophy/>Philosophy</a><a class=tag href=https://www.mseri.me/tags/time/>Time</a><a class=tag href=https://www.mseri.me/tags/ai/>Ai</a><a class=tag href=https://www.mseri.me/tags/rant/>Rant</a></div></div></header><div class=post-content><blockquote><p>â€™Forty-two,â€™ said Deep Thought, with infinite majesty and calm.
&ndash; Douglas Adams, <em>The Hitchhiker&rsquo;s Guide to the Galaxy</em></p></blockquote><p>The narrative on AI keeps swinging between panicked existential threats and overoptimistic hype. Last week, while flu forcefully made sure I sayed in bed, I had time to read some articles in my backlog and really found it disappointing how the discussion has stagnated and keeps revolving around the same points.</p><p>None of the ideas look anywhere new. In <em>The Hitchhiker&rsquo;s Guide to the Galaxy</em>, Douglas Adams already brilliantly satirized on the quest for superintelligence and what will happen with it.</p><p>Our obsession with power is driven by the same need for safety that drives others to finding the ultimate answers to the mysteries of existence. Our AGI, like Deep Thought, will be tasked to compute the answer that will make its owner all-powerful or all-knowledgeable. And, the whole we will get from it, will be an answer pronounced with infinite majesty and calm, that no-one can understand.</p><p>And then, to make sense of it, we will follow this phantomatic AGI in building a more powerful one, that will be tasked to find what the real question is to the answer we got. And we will keep on building more and more powerful AGIs, in a never-ending quest for meaning or power, until we realize that we have been chasing our own tails all along, harming the world and ourselves in the process.</p><p>I hope we will eventually break this loop. I think small specialized models can get a long way in helping us solve real problems, without the need to build mastodontic data centers, sucking up enormous amounts of resources and exhausting storage and computing drives from consumers that would actually need them. All things that are already happening.</p><p>It this the first time in years that electronic prices are skyrocketing, and it is not because of geopolitical issues this time, just greed to get teraflops supremacy in the overhyped AI market.</p><p>This neverending concentration of power is truly problematic. Thechnology is good if it is developed for the benefit of all. It is meant to democratize access to knowledge and improve our lifes. Instaed, right now there seems to be a growing tunnel vision for the future, where only a few big players will have access to the most powerful tools, accumulate even more wealth and power, and run the scene with a complete disconnect from reality, with everyone else left behind. Enshittification in full swing, most players have become too big to fail and soon too big to be regulated.</p><p>Maybe, hopefully?, the bubble will burst before we get to that point. At least, historically, this is what has happened over and over again. I see no reason for this time to be different, besides the technofeudal context in which it is developing. So, I am looking forward to see what our &ldquo;42&rdquo; will be and how the ball will start rolling after that.</p><p>In the meantime, I strongly recommend you to read <em>The Hitchhiker&rsquo;s Guide to the Galaxy</em> if you haven&rsquo;t already, and re-read it otherwise! It has never been more actual, and its hilarious and witty commentary can brighten the darkest of days :)</p></div><div class=post-footer><script src=https://utteranc.es/client.js repo=mseri/mseri.github.io issue-term=pathname label=âœ¨ðŸ’¬âœ¨ theme=photon-dark crossorigin=anonymous async></script></div></article></main></body></html>
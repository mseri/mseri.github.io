<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on A fractal spectrum of tales</title><link>https://www.mseri.me/posts/</link><description>Recent content in Posts on A fractal spectrum of tales</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Tue, 13 Jan 2026 10:12:23 +0100</lastBuildDate><atom:link href="https://www.mseri.me/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Bringing the data back: from the US to us</title><link>https://www.mseri.me/bringing-the-data-back-from-the-us-to-us/</link><pubDate>Tue, 13 Jan 2026 10:12:23 +0100</pubDate><guid>https://www.mseri.me/bringing-the-data-back-from-the-us-to-us/</guid><description>&lt;p>For a while, but especially over the past few months, I have been trying to be increasingly more conscious of the digital tools I use. It is so convenient to rely on the usual US‑based suspects for email, storage, and collaboration, that we may forget that we are their product and that they may take all of our staff away from us in a whim, with no chances to appeal or get it back before we are locked out.&lt;/p></description></item><item><title>Journey in Progress: my experience with meditation</title><link>https://www.mseri.me/journey-in-progress-my-experience-with-meditation/</link><pubDate>Fri, 26 Dec 2025 18:00:00 +0200</pubDate><guid>https://www.mseri.me/journey-in-progress-my-experience-with-meditation/</guid><description>&lt;p>Have you ever felt like you are constantly running behind, never quite in control? If so, you are not alone. For a long time, I felt this way too, and sometimes I still do. But over the past couple of years, I have experienced a shift in my mindset and overall well-being. I hope that sharing this journey might resonate with others who have felt the same way. Reading about others&amp;rsquo; struggles and small victories has always helped me, so I hope this might do the same for someone else.&lt;/p></description></item><item><title>Four months in the University Council</title><link>https://www.mseri.me/four-months-in-the-university-council/</link><pubDate>Thu, 18 Dec 2025 09:10:59 +0100</pubDate><guid>https://www.mseri.me/four-months-in-the-university-council/</guid><description>&lt;p>&lt;em>This is a repost of my original blog post from the Science Faction blog: &lt;a href="https://www.rug.nl/about-ug/organization/administrative-organization/participation-decision-making/uraad/science-faction/blog/the-uc-experience-four-months-later">The UC experience, four months later&lt;/a>. Since university blog posts get archived after a while, I&amp;rsquo;m keeping this copy here for reference.&lt;/em>&lt;/p>
&lt;p>It&amp;rsquo;s been four months since I joined the university council, and I am still quite glad I had this opportunity. So far, it has been a continuous learning process. Not just about the university and the forces shaping it from the inside and out, but also, and maybe more importantly, about how to run large meetings with an open mind and an atmosphere that fosters lively yet respectful discussions.&lt;/p></description></item><item><title>Our first month in the University Council</title><link>https://www.mseri.me/our-first-month-in-the-university-council/</link><pubDate>Mon, 06 Oct 2025 12:00:16 +0200</pubDate><guid>https://www.mseri.me/our-first-month-in-the-university-council/</guid><description>&lt;p>A month has passed since the new &lt;a href="https://www.rug.nl/about-ug/organization/administrative-organization/participation-decision-making/uraad/?lang=en">University Council (UC)&lt;/a> was installed, and I think it&amp;rsquo;s time to look back on what has happened so far, and what seems to lie ahead. When I enlisted I promised myself to help improve the transparency of the discussions and keep an open channel with anybody that could be interested.&lt;/p>
&lt;p>This first month has been a whirlwind of activity, training, and initial discussions. Much of our work so far has focused on preparation: only now I start to see how crucial is to build a good foundation of knowledge and trust for the decisions and actions to come.&lt;/p></description></item><item><title>A Different Way Forward</title><link>https://www.mseri.me/a-different-way-forward/</link><pubDate>Sat, 04 Oct 2025 12:27:29 +0200</pubDate><guid>https://www.mseri.me/a-different-way-forward/</guid><description>&lt;blockquote>
&lt;p>There is a different way forward. Artificial intelligence doesn’t have to be what it is today. We don’t need to accept the logic of unprecedented scale and consumption to achieve advancement and progress. So much of what our society actually needs—better health care and education, clean air and clean water, a faster transition away from fossil fuels—can be assisted and advanced with, and sometimes even necessitates, significantly smaller AI models and a diversity of other approaches. AI alone won’t be enough, either: We’ll also need more social cohesion and global cooperation, some of the very things being challenged by the existing vision of AI development.&lt;/p></description></item><item><title>UnAI Education?</title><link>https://www.mseri.me/unai-education/</link><pubDate>Wed, 01 Oct 2025 17:27:29 +0200</pubDate><guid>https://www.mseri.me/unai-education/</guid><description>&lt;p>I think an update on my previous blog post on &lt;a href="https://www.mseri.me/ai-in-education-some-food-for-thought/">generative AI in education&lt;/a> is in order. The discussion has been evolving, I am starting to see early signs of polarization, and a mix of denial and overly enthusiastic adoption. Ethical considerations, which had been largely ignored for a good while, are finally getting an increasingly relevant role if not in the decision making, at least in the reflections from many academics. And experimentation is picking up, starting to provide some clarity on the ups and downs of the current revolution.&lt;/p></description></item><item><title>AI in Education - Some food for thought</title><link>https://www.mseri.me/ai-in-education-some-food-for-thought/</link><pubDate>Tue, 29 Jul 2025 08:38:51 +0200</pubDate><guid>https://www.mseri.me/ai-in-education-some-food-for-thought/</guid><description>&lt;p>What are we supposed to do about Generative AI in (mathematical) education?&lt;/p>
&lt;p>Many of us have been wrestling with it over the past few months. I certainly don&amp;rsquo;t have a definitive answer, but it&amp;rsquo;s a topic that demands we share what we&amp;rsquo;re thinking and what we&amp;rsquo;re seeing. If anything, it may bring a felt and needed opportunity to finally be able to rethink and reshape the way our education is organized. We discussed this in less uncertain times both in &lt;a href="https://creators.spotify.com/pod/profile/not-just-numbers/episodes/S1E03---Teaching-mathematics--with-Tams-Grbe-and-Ceclia-Salgado-e2bsae3">It&amp;rsquo;s Not Just Numbers&lt;/a> and &lt;a href="https://creators.spotify.com/pod/profile/degrees-of-freedom/episodes/S2-Ep9---Specifications-Grading-e2oida7">various&lt;/a> &lt;a href="https://creators.spotify.com/pod/profile/degrees-of-freedom/episodes/S3E01-Critical-Pedagogy-and-the-Work-of-Paulo-Freire-e2oid9u">episodes&lt;/a> of &lt;a href="https://creators.spotify.com/pod/profile/degrees-of-freedom/episodes/S3E06---Ungrading-e2oidaq">Degrees of Freedom&lt;/a>, our podcasts on mathematics and education respectively.&lt;/p></description></item><item><title>Riemann rearrangement theorem in the browser</title><link>https://www.mseri.me/riemann-rearrangement-theorem/</link><pubDate>Sat, 14 Dec 2024 14:59:53 +0000</pubDate><guid>https://www.mseri.me/riemann-rearrangement-theorem/</guid><description>&lt;p>One of the first exercises when studying convergence of infinite series asks to show that $\sum_{n=1}^{\infty} \frac{1}{n}$ is divergent while $\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}$ is convergent. In more technical terms, $\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}$ is a &lt;a href="https://en.wikipedia.org/wiki/Conditionally_convergent">&lt;strong>conditionally convergent&lt;/strong> series&lt;/a>.&lt;/p>
&lt;p>This is in contrast to &lt;strong>absolutely convergent&lt;/strong> series, that is, infinite sums $\sum_{n=1}^{\infty} a_n$ such that $\sum_{n=1}^{\infty} |a_n|$ is also convergent.&lt;/p>
&lt;p>What is peculiar about conditionally convergent series, is that it is possible to rearrange the terms in the sequence so that the sum of the rearrangement converges to any arbitrary number. This is called &lt;a href="https://en.wikipedia.org/wiki/Riemann_series_theorem">&lt;strong>Riemann&amp;rsquo;s rearrangement theorem&lt;/strong>&lt;/a>.&lt;/p></description></item><item><title>Running LLMs Locally With Ollama</title><link>https://www.mseri.me/running-llms-locally-with-ollama/</link><pubDate>Fri, 26 Jul 2024 11:14:09 +0200</pubDate><guid>https://www.mseri.me/running-llms-locally-with-ollama/</guid><description>&lt;p>In &lt;a href="https://www.mseri.me/running-llms-locally/">my previous post&lt;/a>, I explored various ways to run Large Language Models locally.
Since that post, I have been pointed to try another powerful tool for this purpose: &lt;a href="https://ollama.com/">Ollama&lt;/a>.
This open-source project makes it incredibly easy to run LLMs on your local machine, offering a great balance between simplicity and flexibility.&lt;/p>
&lt;p>While it does not seem as flexible as the &lt;code>llm&lt;/code> python library I presented in the other post and it can scare some users with its command-line interface, I was impressed by its ease of use and the wide range of models it supports.
I am not overselling this, its simplicity is staggering: you can get started with just a few commands.&lt;/p></description></item><item><title>Running LLMs locally</title><link>https://www.mseri.me/running-llms-locally/</link><pubDate>Wed, 24 Jul 2024 18:37:42 +0200</pubDate><guid>https://www.mseri.me/running-llms-locally/</guid><description>&lt;p>Large Language Models (LLMs) are powerful tools for generating human-like text responses. You might be familiar with them through services like &lt;a href="https://chat.openai.com/">ChatGPT&lt;/a>, &lt;a href="https://claude.ai/">Anthropic Claude&lt;/a>, &lt;a href="https://gemini.google.com/">Google Gemini&lt;/a>, and &lt;a href="https://www.perplexity.ai/">Perplexity AI&lt;/a>,
Nowadays people are using them for editing purposes, writing, brainstorming, and even for generating code snippets.
When used &lt;strong>responsibly and critically&lt;/strong> as a tool to assist human creativity, they can be very helpful.&lt;/p>
&lt;p>Recently, I spent some time playing with these models and I found them fascinating. However, due to privacy concerns and their high environmental costs, I don&amp;rsquo;t feel comfortable using cloud-based services.
This post is an account of my experience with running LLMs locally on my machines.
This can be quite straightforward, and if you have 8-16GB of RAM and a decent GPU, you can run these models on your own computer without significant issues.&lt;/p></description></item></channel></rss>